<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <title>Sylvaria Identity Portal — Minimal Test</title>
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <style>
    body{font-family:Segoe UI,Arial,sans-serif;padding:1rem}
    video{width:320px;height:240px;background:#000;display:block;margin-bottom:0.5rem}
    #status{color:#333;margin-bottom:0.5rem}
    button{padding:0.5rem 1rem;border-radius:6px;border:none;background:#2d9cdb;color:#fff}
  </style>
</head>
<body>
  <h3>Sylv Test</h3>
  <div id="status">init</div>
  <video id="video" autoplay muted playsinline></video>
  <div>
    <button id="detectBtn" disabled>Detect Face</button>
  </div>

  <!-- IMPORTANT: load tfjs first, then face-api.js from CDN (no other tfjs/face-api scripts) -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.3.1/dist/tf.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>

  <script>
  (async function(){
    const status = id => document.getElementById('status').textContent = id;
    const video = document.getElementById('video');
    const detectBtn = document.getElementById('detectBtn');

    // sanity log
    console.log('tf:', typeof tf, 'tf.version_core=', tf && tf.version_core);
    console.log('faceapi nets:', Object.keys(faceapi.nets || {}));

    status('Loading models...');
    try {
      await Promise.all([
        faceapi.nets.tinyFaceDetector.loadFromUri('./'),
        faceapi.nets.faceLandmark68Net.loadFromUri('./'),
        faceapi.nets.faceRecognitionNet.loadFromUri('./'),
        faceapi.nets.ageGenderNet.loadFromUri('./')
      ]);
    } catch (e) {
      console.error('Model load error', e);
      status('Model load failed — check console and files.');
      return;
    }
    status('Models loaded. Starting camera...');

    try {
      const s = await navigator.mediaDevices.getUserMedia({ video:true });
      video.srcObject = s;
      await new Promise(resolve=>{
        if (video.readyState >= 2 && video.videoWidth && video.videoHeight) { video.play().catch(()=>{}); resolve(); return; }
        video.onloadedmetadata = ()=>{ video.play().catch(()=>{}); resolve(); };
        setTimeout(resolve,3000);
      });
    } catch (e) {
      console.error('Camera error', e);
      status('Camera failed');
      return;
    }

    status('Ready. Run diagnostics then press Detect.');

    // final diagnostics to paste if error still appears
    console.log('DIAG: video readyState=', video.readyState, 'w/h=', video.videoWidth, video.videoHeight,
                'tf.version_core=', tf.version_core, 'backend=', tf.getBackend && tf.getBackend());
    detectBtn.disabled = false;

    detectBtn.onclick = async () => {
      status('Running detection...');
      // copy this console output if you still get "t is not a function"
      console.log('PRE-DETECT DIAG:', {
        tf_type: typeof tf,
        tf_ver: tf.version_core,
        backend: tf.getBackend && tf.getBackend(),
        video_instance: video instanceof HTMLVideoElement,
        readyState: video.readyState,
        width: video.videoWidth, height: video.videoHeight
      });
      try {
        const det = await faceapi
          .detectSingleFace(video, new faceapi.TinyFaceDetectorOptions())
          .withFaceLandmarks()
          .withFaceDescriptor()
          .withAgeAndGender();
        console.log('detection result:', det);
        if (!det) { status('No face'); alert('No face detected'); return; }
        status('Detected OK — check console for descriptor');
      } catch (err) {
        console.error('DETECT ERROR', err);
        status('Detect error — see console');
        alert('Detect error — copy console output and paste it to me');
      }
    };
  })();
  </script>
</body>
</html>
