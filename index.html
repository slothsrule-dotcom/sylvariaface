<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <title>Sylvaria Identity Portal — Injection-resilient</title>
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <style>
    body{font-family:Segoe UI,Arial,sans-serif;padding:1rem}
    video{width:320px;height:240px;background:#000;display:block;margin-bottom:0.5rem}
    #status{color:#333;margin-bottom:0.5rem}
    button{padding:0.5rem 1rem;border-radius:6px;border:none;background:#2d9cdb;color:#fff}
  </style>
</head>
<body>
  <h3>Sylv Injection-Resilient Test</h3>
  <div id="status">init</div>
  <video id="video" autoplay muted playsinline></video>
  <div><button id="detectBtn" disabled>Detect Face</button></div>

  <script>
  (async function(){
    const statusEl = id => { document.getElementById('status').textContent = id; console.log('[status]', id); };
    const video = document.getElementById('video');
    const detectBtn = document.getElementById('detectBtn');

    // 1) Remove injected TF-like artifacts that may break TFJS registration
    try {
      if (window._tfengine !== undefined) {
        console.warn('Removing injected window._tfengine');
        try { delete window._tfengine; } catch(e) { window._tfengine = undefined; }
      }
      // Remove any stray tf object that looks like non-standard (we'll reload a clean tf)
      if (window.tf !== undefined) {
        // keep note of version if present
        try {
          console.warn('Existing window.tf detected (will remove). version:', window.tf.version_core);
        } catch(e) { console.warn('Existing window.tf detected'); }
        try { delete window.tf; } catch(e) { window.tf = undefined; }
      }
    } catch (e) {
      console.warn('Cleanup exception', e);
    }

    // Helper to load script dynamically and wait
    function loadScript(src) {
      return new Promise((resolve, reject) => {
        const s = document.createElement('script');
        s.src = src;
        s.async = false;
        s.onload = () => resolve();
        s.onerror = (e) => reject(new Error('Failed to load ' + src));
        document.head.appendChild(s);
      });
    }

    // 2) Load the exact matching tfjs and face-api.js versions
    statusEl('Loading tfjs and face-api.js from CDN...');
    try {
      await loadScript('https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.3.1/dist/tf.min.js');
      await loadScript('https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js');
    } catch (err) {
      console.error(err);
      statusEl('Failed to load libraries. Check network or CDN.');
      return;
    }

    // 3) Sanity logs
    console.log('tf typeof', typeof window.tf, 'tf.version_core=', window.tf && window.tf.version_core);
    console.log('faceapi nets', Object.keys(window.faceapi && faceapi.nets || {}));

    // 4) Load models (expect model files to be in same folder as this file)
    statusEl('Loading models...');
    try {
      await Promise.all([
        faceapi.nets.tinyFaceDetector.loadFromUri('./'),
        faceapi.nets.faceLandmark68Net.loadFromUri('./'),
        faceapi.nets.faceRecognitionNet.loadFromUri('./'),
        faceapi.nets.ageGenderNet.loadFromUri('./')
      ]);
    } catch (e) {
      console.error('Model load error', e);
      statusEl('Model load failed — check console and model files.');
      return;
    }

    // 5) Start camera and wait until ready
    statusEl('Starting camera...');
    try {
      const stream = await navigator.mediaDevices.getUserMedia({video:true});
      video.srcObject = stream;
      await new Promise(resolve => {
        if (video.readyState >= 2 && video.videoWidth && video.videoHeight) { video.play().catch(()=>{}); resolve(); return; }
        video.onloadedmetadata = () => { video.play().catch(()=>{}); resolve(); };
        setTimeout(resolve, 3000);
      });
    } catch (e) {
      console.error('Camera error', e);
      statusEl('Camera start failed.');
      return;
    }

    statusEl('Ready. Run diagnostics then press Detect.');
    console.log('DIAG: video readyState=', video.readyState, 'size=', video.videoWidth, 'x', video.videoHeight,
                'tf.version_core=', tf.version_core, 'backend=', tf.getBackend && tf.getBackend());
    detectBtn.disabled = false;

    // 6) Detection handler with diagnostics
    detectBtn.onclick = async () => {
      statusEl('Running detection...');
      console.log('PRE-DETECT DIAG:', {
        tf_type: typeof tf,
        tf_ver: tf.version_core,
        backend: tf.getBackend && tf.getBackend(),
        video_instance: video instanceof HTMLVideoElement,
        readyState: video.readyState,
        width: video.videoWidth, height: video.videoHeight
      });
      try {
        const det = await faceapi
          .detectSingleFace(video, new faceapi.TinyFaceDetectorOptions())
          .withFaceLandmarks()
          .withFaceDescriptor()
          .withAgeAndGender();
        console.log('detection result', det);
        if (!det) { statusEl('No face'); alert('No face detected'); return; }
        statusEl('Detected OK — see console for descriptor');
        alert('Detected OK — check console for descriptor object');
      } catch (err) {
        console.error('DETECT ERROR', err);
        statusEl('Detect error — see console');
        alert('Detect error — copy console output and paste here');
      }
    };
  })();
  </script>
</body>
</html>
